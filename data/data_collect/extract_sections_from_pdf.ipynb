{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF 에서 introduction, related works, background 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data_files/paper_metadata/arxiv_ascending_20161001_20230920.pkl\", 'rb') as f:\n",
    "    paper_meta = pickle.load(f)\n",
    "    \n",
    "with open (\"../data_files/paper_metadata/arxiv_descending_2024_20160927.pkl\", 'rb') as f:\n",
    "    after2023 = pickle.load(f)\n",
    "\n",
    "paper_meta.extend(after2023)\n",
    "paper_total = sorted(paper_meta, key=lambda x: x['published'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdf 에서 필요한 부분 (intro, related_works, background 추출)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyMuPDF 사용해서 논문의 섹션을 인식 후, 필요한 파트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 처리해야하는 사항들\n",
    "# 각주가 있어서 section으로 처리되는 경우 \n",
    "# Introduction, Method와 같이 맨 앞에 숫자가 없는 경우\n",
    "# Introduction, Method와 같이 맨 앞에 로마 숫자인 경우 (해결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_title(title):\n",
    "    title_fixed = title.replace('\\n', ' ').strip()  # 줄바꿈 제거 및 양끝 공백 제거\n",
    "    title_fixed = re.sub(r'\\s+', ' ', title_fixed)  # 여러 공백을 하나로 축소\n",
    "    title_fixed = title_fixed.replace('/', '_')  # '/'를 '_'로 대체\n",
    "    return title_fixed\n",
    "\n",
    "def is_page_number(text): # 페이지 번호도 section으로 취급되는 것을 막기 위해 추가한 함수\n",
    "    \"\"\"\n",
    "    텍스트가 페이지 번호인지 확인하는 함수.\n",
    "    - 단일 숫자 또는 \"Page X\" 형식 등으로 페이지 번호를 판단.\n",
    "    \"\"\"\n",
    "    text = text.strip().lower()\n",
    "    # 단일 숫자 또는 \"page X\" 형식의 텍스트인지 확인\n",
    "    if text.isdigit():  # 숫자로만 구성된 경우\n",
    "        return True\n",
    "    if text.startswith(\"page\") and text[4:].strip().isdigit():  # \"Page 1\", \"page 2\" 등\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "roman_numeral_pattern = re.compile(r\"^(?:[IVXLCDM]+)\\.? \")  # 로마 숫자로 시작, 뒤에 . 또는 공백\n",
    "alphabetic_subheading_pattern = re.compile(r\"^[A-Z]\\. \")     # 알파벳과 점으로 시작 (A., B., C. 등)\n",
    "\n",
    "def extract_sections(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    current_text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"blocks\")  # 페이지 내 텍스트 블록 가져오기\n",
    "        for block in blocks:\n",
    "            text = block[4].strip()  # 블록 텍스트 추출\n",
    "            #print(text)\n",
    "            \n",
    "            # 페이지 번호인지 확인 \n",
    "            if is_page_number(text):\n",
    "                continue\n",
    "            \n",
    "            # 섹션 제목 탐지 (섹션 번호로 시작하는 경우)\n",
    "            if text.startswith(tuple(str(i) for i in range(1, 10))) or roman_numeral_pattern.match(text):  # \"1\", \"2\" 등으로 시작\n",
    "                if current_section:  # 현재 섹션 저장\n",
    "                    sections.append((current_section, current_text.strip()))\n",
    "                current_section = text  # 새로운 섹션 제목\n",
    "                #print(current_section)\n",
    "                current_text = \"\"  # 섹션 텍스트 초기화\n",
    "                \n",
    "            # 2. 알파벳 소제목 감지 (A., B., C. 등)\n",
    "            elif alphabetic_subheading_pattern.match(text):\n",
    "                current_text += f\"\\n{text}\\n\"  # 기존 섹션 본문에 추가\n",
    "            \n",
    "            else:\n",
    "                current_text += f\"{text} \"  # 섹션 본문 추가\n",
    "\n",
    "    # 마지막 섹션 추가\n",
    "    if current_section:\n",
    "        sections.append((current_section, current_text.strip()))\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하위 섹션 여부를 판단하는 함수\n",
    "def is_subsection_of(parent, child):\n",
    "    \"\"\"\n",
    "    주어진 `child` 섹션이 `parent` 섹션의 하위인지 확인.\n",
    "    숫자와 로마 숫자 모두 처리.\n",
    "    \"\"\"\n",
    "    if parent.isdigit():  # 숫자 섹션 (예: 2.1, 2.2)\n",
    "        return child.startswith(parent)\n",
    "    else:  # 로마 숫자 섹션 (예: II.A, II.B)\n",
    "        return child.split(\".\")[0] == parent\n",
    "\n",
    "# introduction, related_works, background 추출\n",
    "def extract_specific_section(file_path, target_section):\n",
    "    \"\"\"\n",
    "    특정 섹션과 그 하위 내용을 추출.\n",
    "    - 타겟 섹션 번호 아래 A., B., C. 같은 알파벳 소제목 포함.\n",
    "    \"\"\"\n",
    "    # 타겟 섹션 이름과 대소문자 및 복수형을 포함해 매칭할 정규 표현식 생성\n",
    "    target_section_pattern = re.compile(\n",
    "        rf\"{re.escape(target_section)}(s)?\", re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # 숫자 및 로마 숫자 섹션 추출 정규식\n",
    "    section_num_pattern = re.compile(r\"^(\\d+|I{1,3}|IV|V|VI|VII|VIII|IX|X)(\\b|\\.|\\s)\")\n",
    "    \n",
    "    # 알파벳 소제목(A., B., ...) 정규식\n",
    "    alphabetic_subheading_pattern = re.compile(r\"^[A-Z]\\.\\s\")\n",
    "\n",
    "    sections = extract_sections(file_path)\n",
    "    extracted_text = \"\"\n",
    "    start_section_num = None\n",
    "    current_major_section = None  # 현재 주요 섹션 번호 저장\n",
    "\n",
    "    for section_title, section_text in sections:\n",
    "        # 숫자 또는 로마 숫자로 시작하는 섹션 번호 추출\n",
    "        section_num_match = section_num_pattern.match(section_title)\n",
    "        section_num = section_num_match.group(1) if section_num_match else None\n",
    "        \n",
    "        # 1. 타겟 섹션 시작 감지\n",
    "        if start_section_num is None and target_section_pattern.search(section_title):\n",
    "            start_section_num = section_num  # 타겟 섹션 번호 저장 (예: II)\n",
    "            current_major_section = section_num\n",
    "            extracted_text += f\"{section_title}\\n{section_text}\\n\"\n",
    "\n",
    "        # 2. 타겟 섹션 번호 또는 하위 섹션 포함 (예: II.A, II.B)\n",
    "        # section_num.startswith(start_section_num) 이걸로 하면 III 은 II로 시작하는게 맞아서 수정되어버림 아오ㅓ\n",
    "        elif start_section_num and section_num and is_subsection_of(start_section_num, section_num):\n",
    "            current_major_section = section_num.split(\".\")[0]  # 주요 섹션 번호 업데이트\n",
    "            extracted_text += f\"{section_title}\\n{section_text}\\n\"\n",
    "\n",
    "        # 3. 알파벳 소제목(A., B., C.) 포함 (현재 주요 섹션에 속하는 경우만)\n",
    "        elif current_major_section and alphabetic_subheading_pattern.match(section_title):\n",
    "            extracted_text += f\"{section_title}\\n{section_text}\\n\"\n",
    "\n",
    "        # 4. 새로운 주요 섹션으로 넘어가면 종료\n",
    "        elif start_section_num and section_num and start_section_num != section_num:\n",
    "            break\n",
    "\n",
    "    return extracted_text if extracted_text else f\"CODE998825\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70000 papers so far...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Papers: 100%|██████████| 70000/70000 [4:44:12<00:00,  4.11it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 에러 로그 저장\n",
    "logging.basicConfig(\n",
    "    filename=\"processing_pdf_after_error_intro.log\",  # 로그 파일 이름\n",
    "    filemode=\"w\",                  # 로그 파일 덮어쓰기\n",
    "    level=logging.INFO,            # 로그 레벨 설정 (INFO 이상)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "def is_valid_pdf(file_path):\n",
    "    \"\"\"PDF 파일 유효성 검사.\"\"\"\n",
    "    try:\n",
    "        with fitz.open(file_path) as doc:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Invalid PDF: {file_path} - Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# 처리 진행\n",
    "for idx, paper in enumerate(tqdm(paper_total, desc=\"Processing Papers\")):\n",
    "    try: \n",
    "        entry_id = paper['entry_id'].split('/')[-1]\n",
    "        title = sanitize_title(paper['title'])\n",
    "        author = ', '.join(paper['authors'])\n",
    "        \n",
    "        published = datetime.strftime(paper['published'], format='%Y-%m-%d')\n",
    "        published_year = published.split('-')[0]\n",
    "        published_month = published.split('-')[1]\n",
    "        published_day = published.split('-')[2]\n",
    "        \n",
    "        abstract = paper['summary']\n",
    "        paper_link = paper['links'][1]\n",
    "        pdf_file_path = f'../paper_연도별/paper_{published_year}/{title}.pdf'\n",
    "        \n",
    "        if not os.path.exists(pdf_file_path) or not is_valid_pdf(pdf_file_path):\n",
    "            logging.warning(f\"Skipping invalid or missing PDF: {pdf_file_path}\")\n",
    "            introduction = \"CODE 997725\"\n",
    "            related_work = \"CODE 997725\"\n",
    "            background = \"CODE 997725\"\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                introduction = extract_specific_section(pdf_file_path, 'Introduction')\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting 'Introduction' in '{title}' (Path: {pdf_file_path}): {e}\")\n",
    "                introduction = \"CODE 997725\"\n",
    "            \n",
    "            try:\n",
    "                related_work = extract_specific_section(pdf_file_path, 'Related Work')\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting 'Related Work' in '{title}' (Path: {pdf_file_path}): {e}\")\n",
    "                related_work = \"CODE 997725\"\n",
    "\n",
    "            try:\n",
    "                background = extract_specific_section(pdf_file_path, 'Background')\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error extracting 'Background' in '{title}' (Path: {pdf_file_path}): {e}\")\n",
    "                background = \"CODE 997725\"\n",
    "        \n",
    "        # 데이터를 리스트로 추가\n",
    "        data.append({\n",
    "            \"entry_id\": entry_id,\n",
    "            \"title\": title,\n",
    "            \"author\": author,\n",
    "            \"published\": published,\n",
    "            \"published_year\": published_year,\n",
    "            \"published_month\": published_month,\n",
    "            \"published_day\": published_day,\n",
    "            \"abstract\": abstract,\n",
    "            \"introduction\": introduction,\n",
    "            \"paper_link\": paper_link,\n",
    "            \"related_work\": related_work,\n",
    "            \"background\": background\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing paper with entry_id {paper['entry_id']}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # 매 200개마다 출력 초기화\n",
    "    if (idx + 1) % 200 == 0:\n",
    "        clear_output(wait=True)  # 이전 출력 삭제\n",
    "        print(f\"Processed {idx + 1} papers so far...\")  # 진행 상황 표시\n",
    "    \n",
    "    # 매 10000개마다 백업 저장\n",
    "    if (idx + 1) % 10000 == 0:\n",
    "        df = pd.DataFrame(data)\n",
    "        backup_filename = f\"../data_files/filtered_data/backup_data/processed_papers_backup_end_{idx + 1}.parquet\"\n",
    "        df.to_parquet(backup_filename, index=False)\n",
    "        logging.info(f\"Backup saved at {backup_filename}\")\n",
    "\n",
    "# 최종 데이터프레임 저장\n",
    "df = pd.DataFrame(data)\n",
    "df.to_parquet(\"../data_files/filtered_data/processed_papers.parquet\", index=False)\n",
    "logging.info(\"Final processed papers saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
